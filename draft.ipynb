{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"correctness\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"description\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Reasoning behind the characteristic evaluation\",\n",
    "                },\n",
    "                \"score\": {\"type\": \"string\", \"description\": \"Mark; One of [A, B, C, D]\"},\n",
    "            },\n",
    "            \"description\": \"Evaluation of the correctness of the text from the grammar perspective\",\n",
    "            \"required\": [\"description\", \"score\"],\n",
    "        },\n",
    "        \"politeness\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"description\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Reasoning behind the characteristic evaluation\",\n",
    "                },\n",
    "                \"score\": {\"type\": \"string\", \"description\": \"Textual mark\", \"enum\": [\"A\", \"B\", \"C\", \"D\"]},\n",
    "            },\n",
    "            \"description\": \"Evaluation of the text from the politeness perspective\",\n",
    "            \"required\": [\"description\", \"score\"],\n",
    "        },\n",
    "\n",
    "    },\n",
    "    \"required\": [\"ingredients\", \"instructions\", \"time_to_cook\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"For number 2 it depends on what you are trying to achieve, but you might want to leverage cronJob errors that are already pushed into Datadog, instead of trying to connect with lambda. You can see [Cheating Detection] related monitors here as an example, but in short, you can monitor for codeQuality.calculateScreenCodeQuality.jobFailed as the first sign that something is bad (e.g. right now there seem to be 400 error cases?).\n",
    "You can also sprinkle in some @error:\"Error: Job failed too many times, removing it from the queue\" to focus on failed jobs.\n",
    "Note, if you are going to look into cheating detection examples, some logs are coming not from the cronJob - they are manually raised in the main app based on the lambda response\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"correctness\": {\n",
      "    \"description\": \"The text is grammatically correct. It uses appropriate punctuation, correct sentence structure, and proper use of technical terms. The use of parentheses to provide additional information is also correct.\",\n",
      "    \"score\": \"A\"\n",
      "  },\n",
      "  \"politeness\": {\n",
      "    \"description\": \"The text is polite and professional. It provides helpful suggestions and guidance without being condescending or dismissive. The use of 'you might want to' and 'you can' phrases makes the suggestions sound more like friendly advice rather than orders.\",\n",
      "    \"score\": \"A\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-4-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Provide an alalysis of the text: {text}\"},\n",
    "    ],\n",
    "    functions=[{\"name\": \"set_text_properties\", \"parameters\": schema}],\n",
    "    function_call={\"name\": \"set_text_properties\"},\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.function_call.arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"correctness\": {\n",
      "    \"description\": \"The text is mostly grammatically correct, but there is one error. The phrase 'I’ve wrote a lot in the issue' should be 'I’ve written a lot in the issue'.\",\n",
      "    \"score\": \"B\"\n",
      "  },\n",
      "  \"politeness\": {\n",
      "    \"description\": \"The text is polite. It uses respectful language and does not contain any offensive or inappropriate words.\",\n",
      "    \"score\": \"A\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.function_call.arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
